{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import tensorflow_io as tfio\n",
    "import numpy as np\n",
    "from configs import Configs as C\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function that will use the txt files in the data to create arrays of file paths  \n",
    "#  basedir = ./data/\n",
    "def txt_file_path_loader(file_path, base_dir = '/data/'):\n",
    "    with open(file_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    file_paths = [base_dir + line.strip() for line in lines]\n",
    "    return file_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting stereo audio into mono for 1d convelution and training\n",
    "def convert_to_mono(wav):\n",
    "    return tf.reduce_mean(wav, axis = -1, keepdims= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_wav(wav, og_sample_rate, target_sample_rate):\n",
    "        # Calculate the number of samples needed for 16kHz\n",
    "        duration = tf.shape(wav)[0] / og_sample_rate\n",
    "        new_sample_count = tf.cast(duration * target_sample_rate, tf.int32)\n",
    "        \n",
    "        # Resample using tf.image.resize with 1D signal\n",
    "        resampled = tf.image.resize(\n",
    "            tf.expand_dims(wav, -1), #image representation\n",
    "            [new_sample_count, 1], \n",
    "            method='bilinear'\n",
    "        )\n",
    "        \n",
    "        return tf.squeeze(resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to take in a file path and load and prepare an audio file\n",
    "def prepare_wav(file_path, target_rate):\n",
    "    # load audio file in\n",
    "    audio_binary = tf.io.read_file(file_path)\n",
    "    wav, sample_rate = tf.audio.decode_wav(audio_binary)\n",
    "\n",
    "    # Resample to 16kHz if necessary\n",
    "    if sample_rate != target_rate:\n",
    "        wav = resample_wav(wav, sample_rate, target_rate)\n",
    "\n",
    "    # Convert to mono by taking the first channel if stereo\n",
    "    if wav.shape[-1] > 1 :\n",
    "        wav = convert_to_mono(wav)\n",
    "\n",
    "    return wav\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wav_to_spectrogram(wav_tensor, nfft, window, stride):\n",
    "    return tfio.audio.spectrogram(\n",
    "        wav_tensor, \n",
    "        nfft,\n",
    "        window,\n",
    "        stride\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function that is going to take in a set of file paths and retrun the appriopriate X and Y object for that data\n",
    "def batch_generator(X_file_paths, batch_size, target_rate, nfft, window, stride):\n",
    "    x_data = []\n",
    "    y_data = []\n",
    "\n",
    "    batch_length_count = 0\n",
    "    for x_path in X_file_paths:\n",
    "        # iterate thorugh files and create a data set for using those file paths\n",
    "        \n",
    "        # get label for path by splitting and indexing into secound item (first is base dir)\n",
    "        label = x_path.split(os.path.sep)[1]\n",
    "        # create one hot encoding for softmax\n",
    "        one_hot = np.ones(C.num_classes)\n",
    "        one_hot_index = C.label_encodings[label]\n",
    "        one_hot[one_hot_index] = 1\n",
    "\n",
    "        # prepare spectrogram\n",
    "        wav = prepare_wav(x_path, target_rate)\n",
    "        spectrogram = wav_to_spectrogram(wav, nfft, window, stride)\n",
    "        # logormithic normalziation of spectrogram\n",
    "        spectrogram = tf.cast(spectrogram, tf.float32)\n",
    "        spectrogram = tf.math.log1p(spectrogram) #log1p is a better version of log + epsillon\n",
    "\n",
    "        # add data to dataset\n",
    "        batch_length_count += 1\n",
    "        x_data.append(spectrogram)\n",
    "        y_data.append(one_hot)\n",
    "\n",
    "        if batch_length_count >= batch_size:\n",
    "            # pre pare and yield batch\n",
    "            batched_x_data = np.array(x_data[:batch_size])\n",
    "            batched_y_data = np.array(y_data[:batch_size])\n",
    "            yield batched_x_data, batched_y_data\n",
    "            # remove yielded data\n",
    "            x_data = x_data[batch_size:]\n",
    "            y_data = y_data[batch_size:]\n",
    "            # reduce counter\n",
    "            batch_length_count -= batch_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_spectrogram_dimensions(target_rate, nfft, window, stride):\n",
    "    height = (nfft // 2) + 1\n",
    "\n",
    "    # Calculate width (time frames)\n",
    "    width = math.ceil((target_rate - window) / stride) + 1\n",
    "\n",
    "    return height, width "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A function to create tensorflow data set for better GPU acceleration during training, validation and testing\n",
    "def create_dataset(X_file_paths, batch_size, target_rate, nfft, window, stride  ):\n",
    "    num_classes = C().num_classes\n",
    "    # calcualte  spectrogram height and width\n",
    "    height, width = calculate_spectrogram_dimensions(target_rate, nfft, window, stride)\n",
    "    \n",
    "    dataset = tf.data.Dataset.from_generator(\n",
    "        lambda: batch_generator(X_file_paths, batch_size, target_rate, nfft, window, stride),\n",
    "        output_signature = (\n",
    "            tf.TensorSpec(shape=(batch_size, height, width, 1 ), dtype= tf.float32), #define the shape of X's and Y's\n",
    "            tf.TensorSpec(shape=(batch_size, num_classes), dtype=tf.int32)\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return dataset\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
